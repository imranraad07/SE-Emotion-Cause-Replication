Comment,Cause,Cluster
@sdeoras Your original issue looks like you have a bad version of tensorflow_io_gcs_filesystem installed. For building TensorFlow 2.11.x please use tensorflow_io_gcs_filesystem==0.31.0.,"""Your original issue looks like you have a bad version of tensorflow_io_gcs_filesystem installed.""",1
"Hi guanyu, this seems a tooling issue on tensorflow side. Could you help file a separate issue for this?","""This seems a tooling issue on tensorflow side.""",1
@SuryanarayanaY You are missing an install of keras and tensorflow-estimator. Or alternatively keras-nightly and tf-estimator-nightly.,"""You are missing an install of keras and tensorflow-estimator. Or alternatively keras-nightly and tf-estimator-nightly.""",1
"Hi @SajjadAemmi ,
It seems the version compatibility between tensorflow and tensorflow-io causing the problem.
Can you try installing tensorflow-io alongwith its compatible tensorflow using the below code.
`!pip install tensorflow-io[tensorflow]`
For me the reported Import error gone with above installation code.Please refer to attached [gist](https://colab.research.google.com/gist/SuryanarayanaY/ad1c1c1af38ca6c5a6a80805751426cb/58762_r2.ipynb).","""It seems the version compatibility between tensorflow and tensorflow-io causing the problem.""",1
"I see a failure on tensorflow/compiler/mlir/tosa/tests:tfl-to-tosa-pipeline.mlir.test , could you check locally?","I see a failure on tensorflow/compiler/mlir/tosa/tests:tfl-to-tosa-pipeline.mlir.test , could you check locally?",1
"@sachinprasadhs,
I was able to reproduce the issue on tensorflow [v2.11](https://colab.research.google.com/gist/tilakrayal/4212b2c3d4ede31976079649f401eef1/untitled841_gpu.ipynb) and nightly and the error was Python process crashing. Kindly find the gist of it [here](https://colab.research.google.com/gist/tilakrayal/8f3c41bc045d1a3d65f5f692b764f9ca/untitled914.ipynb).",I was able to reproduce the issue on tensorflow [v2.11](https://colab.research.google.com/gist/tilakrayal/4212b2c3d4ede31976079649f401eef1/untitled841_gpu.ipynb) and nightly and the error was Python process crashing.,1
"@sushreebarsa, I was able to replicate the issue in [TF v2.10](https://colab.sandbox.google.com/gist/synandi/c853a7c8d51e9412152c988f70c3475a/59343_2-10.ipynb) and [TF v2.11](https://colab.sandbox.google.com/gist/synandi/eaf3157cad81ea56a6c7751492618aca/59343_2-11.ipynb) in colab. Could you please check this issue?",I was able to replicate the issue in [TF v2.10](https://colab.sandbox.google.com/gist/synandi/c853a7c8d51e9412152c988f70c3475a/59343_2-10.ipynb) and [TF v2.11](https://colab.sandbox.google.com/gist/synandi/eaf3157cad81ea56a6c7751,1
"I still see below issue with tf-nighty
0x00007fffcb614553 in mlir::quant::QuantizedType::getExpressedType() const () from ~whisper-tflite/venv/lib/python3.10/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so",I still see below issue with tf-nighty 0x00007fffcb614553 in mlir::quant::QuantizedType::getExpressedType() const () from whisper-tflite/venv/lib/python3.10/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so.,1
Can someone from Google take this over? I tried several test cases but non of them can capture this bug in tensorflow.,I tried several test cases but non of them can capture this bug in tensorflow.,1
"@apivovarov I tried to replicate the issue on colab using tf-nightly, and faced `RuntimeError: Tensorflow has not been built with TensorRT support`. Please find the gist [here](https://colab.research.google.com/gist/sushreebarsa/c6be14b1375c204f48de99e30c521d04/58248.ipynb) and confirm the same?
Thank you!","""RuntimeError: Tensorflow has not been built with TensorRT support""",1
"@sachinprasadhs,
I was able to reproduce the issue on tensorflow [v2.9](https://colab.research.google.com/gist/tilakrayal/fc3bb093faa07f69c6e82f49cb1efdd9/untitled831.ipynb), [v2.11](https://colab.research.google.com/gist/tilakrayal/01952d120576ddb7108abad1625fbadb/untitled832.ipynb) and [nightly](https://colab.research.google.com/gist/tilakrayal/2075154ea5c2a250e9399e97ea0ba2f3/untitled833.ipynb). Kindly find the gist.",I was able to reproduce the issue on tensorflow [v2.9](https://colab.research.google.com/gist/tilakrayal/fc3bb093faa07f69c6e82f49cb1efdd9/untitled831.ipynb),1
"@Neizvestnyj ,
I observed you installed tensorflow-cpu==2.10 and it seems you are trying to use GPU also. Since Windows native can support GPU for TF <=2.10 v could you uninstall tensorflow and then try removing cpu tag with `pip install tensorflow==2.10` and let us know if problem still persists.","""I observed you installed tensorflow-cpu==2.10 and it seems you are trying to use GPU also.""",1
"`//tensorflow/compiler/xla/tools:run_hlo_module` is also broken.
Can the build of one of those 2 tools (or both) be included in the CI?
It isn't great to have our basic tools broken for over a week now.",//tensorflow/compiler/xla/tools:run_hlo_module is also broken.,1
"@LIONEFAN,
Sorry for the delay. I tried on tensorflow v2.10 to reproduce the issue but I was not able to fetch the files which are mentioned. Kindly find the [gist](https://colab.research.google.com/gist/tilakrayal/a78bb5afe17b093e69cb489d2281cf12/2-1000000.ipynb) and the image for the reference.
![image](https://user-images.githubusercontent.com/81610181/208050074-5c7115bc-fdaf-47f1-b923-e989b9bb1877.png)",I tried on tensorflow v2.10 to reproduce the issue but I was not able to fetch the files which are mentioned.,1
Looks like tf_runtime needs to be fixed first.,Looks like tf_runtime needs to be fixed first.,1
Probably yes. I have the same issue with TF 2.11.0 and TensorRT 8.5.1-1+cuda11.8.,I have the same issue with TF 2.11.0 and TensorRT 8.5.1-1+cuda11.8.,1
"> Saving it using the newest version of Tensorflow 1? It only occurs when saving a model in Tensorflow 1 and I tried with Tensorflow 1.15 which should be the newest version.
Try saving the model in Tensorflow version 2.5 and above, for migrating your 1.x code to 2.x, you can follow https://www.tensorflow.org/guide/migrate",Saving it using the newest version of Tensorflow 1?,1
Saving it using the newest version of Tensorflow 1? It only occurs when saving a model in Tensorflow 1 and I tried with Tensorflow 1.15 which should be the newest version.,Saving it using the newest version of Tensorflow 1?,1
"Unfortunately this was rolled back in 970c3b44ea8b0db78d92ada624f03aeacf2e4518 because it broke the TF serving build. @learning-to-play, can you debug this or triage?","""Unfortunately this was rolled back in 970c3b44ea8b0db78d92ada624f03aeacf2e4518 because it broke the TF serving build.""",1
"@sachinprasadhs,
I was able to reproduce the issue on tensorflow-gpu v2.9 and nightly whereas on [cpu](https://colab.research.google.com/gist/tilakrayal/3f5ad2b8c85bc3b85d5ff26e808f0419/cpu.ipynb), the code was able to execute without any issues/error. Kindly find the gist of it [here](https://colab.research.google.com/gist/tilakrayal/56a3bdd6a9e646999d77e49eb8ac4adf/gpu.ipynb).","I was able to reproduce the issue on tensorflow-gpu v2.9 and nightly whereas on [cpu](https://colab.research.google.com/gist/tilakrayal/3f5ad2b8c85bc3b85d5ff26e808f0419/cpu.ipynb), the code was able to execute without any issues/error.",1
"> @rishikasinha-tf, would it be possible to include the PR in a TF 2.10.1 release? The log message is confusing as it (incorrectly) implies that an error has occurred that would prevent TF from running correctly.
Please send a cherrypick PR for `r2.10` too to fix the error message. See [go/tf-release/cherrypick](https://goto.google.com/tf-release/cherrypick) (internal link)",The log message is confusing as it (incorrectly) implies that an error has occurred that would prevent TF from running correctly.,1
"@jiannanWang,
Sorry for the delay. I tried to execute the code on tensorflow-gpu and the results are the same in both cases. Kindly find the gist of it [here](https://colab.research.google.com/gist/tilakrayal/76627395e7ec322a3c5b34bbe586c7fb/untitled660.ipynb).",I tried to execute the code on tensorflow-gpu and the results are the same in both cases.,1
"@sachinprasadhs,
I was able to reproduce the issue on tensorflow v2.8, v2.9 and [nightly](https://colab.research.google.com/gist/tilakrayal/6ec9204828bcc1a63fc2a70bf16f5747/untitled594.ipynb) with and without the line `tf.compat.v1.disable_eager_execution().` Kindly find the gist of it [here](https://colab.research.google.com/gist/tilakrayal/0c33fe9588906eafd35f134f9815e234/untitled581.ipynb).","I was able to reproduce the issue on tensorflow v2.8, v2.9 and [nightly](https://colab.research.google.com/gist/tilakrayal/6ec9204828bcc1a63fc2a70bf16f5747/untitled594.ipynb) with and without the line tf.compat.v1.disable_eager_execution().",1
"I expect this bug to be gone in TF2, and TF1 is no longer officially supported by TensorFlow team. Can you provide a TF2-based repro, one that does not use Sessions?","""I expect this bug to be gone in TF2 and TF1 is no longer officially supported by TensorFlow team.""",1
"@mohantym Can you please reopen this issue? I find I have to address it after upgrading to TensorFlow 2.10
Also, this issue should be with a ""bug"" label.","I find I have to address it after upgrading to TensorFlow 2.10 Also, this issue should be with a ""bug"" label.",1
"Hi @trungnhat-incoder, `ERROR: D:/nghich/tensorflow/tensorflow/BUILD:1035:21: //tensorflow:libtensorflow_framework.so.2.11.0: no such attribute 'shared_lib_name' in 'cc_shared_library' rule`
Tensorflow master branch has `cc_shared_library rule`. Please take a look at this reference [link](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tensorflow.bzl#L2971). Could you build Tf master branch and check. Thank you!","""Error: D:/nghich/tensorflow/tensorflow/BUILD:1035:21: //tensorflow:libtensorflow_framework.so.2.11.0: no such attribute 'shared_lib_name' in 'cc_shared_library' rule""",1
"Hi really sorry for the late reply. I'm working on a fix. In the meantime, can you try tensorflow/lite/ios/build_frameworks.sh? You might need to add `--config=monolithic` when building TensorFlowLiteSelectTfOps_framework.","I'm working on a fix. In the meantime, can you try tensorflow/lite/ios/build_frameworks.sh? You might need to add --config=monolithic when building TensorFlowLiteSelectTfOps_framework.",1
"@sachinprasadhs,
I was able to reproduce the issue on tensorflow v2.9 and nightly. Kindly find the gist of it [here](https://colab.research.google.com/gist/tilakrayal/775dc8ff4e3d8bb2b7c7dfbac78db7d3/untitled502.ipynb) and the issue was reproducible on all int datatype(**int8, int16, int32, int64)**, but was able to execute without any issue on other datatypes (**bfloat16, half, float32, float64, complex64, complex128)**","""I was able to reproduce the issue on tensorflow v2.9 and nightly""",1
"> `ERROR: T:/src/github/tensorflow/tensorflow/python/util/BUILD:189:27: Linking tensorflow/python/util/_pywrap_checkpoint_reader.so failed: (Exit 1120): link.exe failed: error executing command`
Windows build has failed. Let me try to rerun it.",Error: T:/src/github/tensorflow/tensorflow/python/util/BUILD:189:27: Linking tensorflow/python/util/_pywrap_checkpoint_reader.so failed: (Exit 1120): link.exe failed: error executing command,1
"Please make sure all header inclusions are also paired with the corresponding BUILD rules. Internal tests are now failing because of
```
.../tensorflow/c/kernels_experimental.cc:30:10: error: module //.../tensorflow/c:kernels_experimental does not depend on a module exporting '.../tensorflow/core/kernels/tensor_list.h'; to fix run:
build_cleaner //.../tensorflow/c:kernels_experimental
#include "".../tensorflow/core/kernels/tensor_list.h""
```"," .../tensorflow/c/kernels_experimental.cc:30:10: error: module //.../tensorflow/c:kernels_experimental does not depend on a module exporting '.../tensorflow/core/kernels/tensor_list.h'; to fix run: build_cleaner //.../tensorflow/c:kernels_experimental #include "".../tensorflow/core/kernels/tensor_list",1
"@pindinagesh, could you redirect this question to TF repo? It looks more like a TF issue.","""It looks more like a TF issue.""",1
"Hi @wangzy0327,
Delete the tensorflow repo, re-clone and try again, it starts compiling:
```
bazel clean --expunge
rm -rf /packages/tensorflow
!git clone tensorflow
cd /packages/tensorflow
./configure
bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package
```","Delete the tensorflow repo, re-clone and try again, it starts compiling.",1
You should be able to see wrong results on `bazel test -c opt //tensorflow/compiler/xla/tests:dot_operation_test_cpu` https://source.cloud.google.com/results/invocations/e217cb81-ca26-408d-ac6f-b4f8da0e081c/log,"""should be able to see wrong results on bazel test -c opt //tensorflow/compiler/xla/tests:dot_operation_test_cpu https://source.cloud.google.com/results/invocations/e217cb81-ca26-408d-ac6f-b4f8da0e081c/log""",1
"`tf.contrib` module has been deprecated, as the error message suggests, use the OP which does not make use of OP from deprecated tf.contrib.","tf.contrib module has been deprecated, as the error message suggests, use the OP which does not make use of OP from deprecated tf.contrib.",1
"> I would expect something along the lines of https://cs.opensource.google/tensorflow/tensorflow/+/master:tensorflow/compiler/jit/mark_for_compilation_pass_test.cc;l=180-197
Test fail with
`bazel test -test_env=TF_XLA_FLAGS=--tf_xla_cluster_exclude_ops=Where --config=cuda -c opt //tensorflow/compiler/jit:compilation_passes_test `
and pass with `bazel test --config=cuda -c opt //tensorflow/compiler/jit:compilation_passes_test `
which are as expected. @cheshire Could you review the changes?","""Test fail with bazel test -test_env=TF_XLA_FLAGS=--tf_xla_cluster_exclude_ops=Where --config=cuda -c opt //tensorflow/compiler/jit:compilation_passes_test  and pass with bazel test --config=cuda -c opt //tensorflow/compiler/jit:compilation_passes_test  which are as expected.""",1
"It's probably not a bug in Tensorflow but Apple's tensorflow metal plugin. See for example the following discussion https://developer.apple.com/forums/thread/689299 or this one https://developer.apple.com/forums/thread/697057?answerId=704830022#704830022
The solution is to run operations from `tf.random` and `tf.sort` and `tf.argsort` on the CPU like this:
```python
with tf.device('/cpu:0'):
tf.random.uniform((10,))
```","""It's probably not a bug in Tensorflow but Apple's tensorflow metal plugin.""",1
"@dbl001,
Sorry for the late response. I tried with the latest version on MacOS Monetery 12.3.1 and it is working. Could you try with the latest tensorflow (TF2.9) as shown below ```
pip3 install tensorflow-macos
import tensorflow as rf
```",I tried with the latest version on MacOS Monetery 12.3.1 and it is working. Could you try with the latest tensorflow (TF2.9) as shown below  pip3 install tensorflow-macos import tensorflow as rf .,1
"@gowthamkpr,
I was able to reproduce the issue on tensorflow-gpu [v2.8](https://colab.research.google.com/gist/tilakrayal/41ccd32091cfba1720c93fc30cbf306f/2-8_gpu.ipynb) and v2.9. In tensorflow-cpu [v2.8](https://colab.research.google.com/gist/tilakrayal/6ad3790641f539bedd86ab5338617585/2-8-56312.ipynb), i was not able to find the issue. Please find the gist.","""I was able to reproduce the issue on tensorflow-gpu [v2.8](https://colab.research.google.com/gist/tilakrayal/41ccd32091cfba1720c93fc30cbf306f/2-8_gpu.ipynb) and v2.9. In tensorflow-cpu [v2.8](https://colab.research.google.com/gist/tilakrayal/6ad",1
"@gowthamkpr ,
I was able to reproduce the issue in tensorflow [v2.8](https://colab.research.google.com/gist/tilakrayal/1e3b0be6e3530f5bd0a50ce0e88da509/text_generation.ipynb), and in [v2.7](https://colab.research.google.com/gist/tilakrayal/8016913e447c36af168fbf85f98e8d5e/text_generation.ipynb) and nightly the code was failing with different error. Please find the gist.","I was able to reproduce the issue in tensorflow [v2.8](https://colab.research.google.com/gist/tilakrayal/1e3b0be6e3530f5bd0a50ce0e88da509/text_generation.ipynb), and in [v2.7](https://colab.research.google.com/gist/tilakrayal/8016913e447c36af168fbf85f98e",1
"I got the same issue when building TensorFlow 2.9 with CUDA 10.1, among a lot of `.cu.cc` files. Finally, I decided to use CUDA 10.2 instead, and the errors disappeared. It's still quite confusing why 10.2 doesn't have this issue.","I got the same issue when building TensorFlow 2.9 with CUDA 10.1, among a lot of .cu.cc files.",1
"Yes. I just run with command:
```bazelisk test tensorflow/compiler/mlir:all --cache_test_results=no```
and all pass, It seem some test no run.","I just run with command: bazelisk test tensorflow/compiler/mlir:all --cache_test_results=no and all pass, It seem some test no run.",1
"@OrazioLombardi,
```
ERROR: C:/users/priva/tensorflow/tensorflow/core/kernels/BUILD:1222:18: C++ compilation of rule '//tensorflow/core/kernels:inplace_ops_gpu' failed (Exit 1): python.exe failed: error executing command
cd C:/users/priva/_bazel_priva/5lyc5377/execroot/org_tensorflow
```
Looks issue with MSVC2019.
Make sure you followed steps mentioned [here](https://www.tensorflow.org/install/source_windows) and install required packages. Thanks !",ERROR: C:/users/priva/tensorflow/tensorflow/core/kernels/BUILD:1222:18: C++ compilation of rule '//tensorflow/core/kernels:inplace_ops_gpu' failed (Exit 1): python.exe failed: error executing command cd C:/users/priva/_bazel_priva/5lyc5377/execroot/org_tensorflow  Looks issue with MS,1
"@ayaka14732,
Can you try to clear the bazel cache before building Tensorflow
`bazel clean --expunge`",Can you try to clear the bazel cache before building Tensorflow bazel clean --expunge,1
"@tilakrayal No, it's not resolved. Cannot execute ```
./bazel-bin/external/org_tensorflow/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg
```",Cannot execute  ./bazel-bin/external/org_tensorflow/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg .,1
This fails with `ModuleNotFoundError: No module named 'tensorflow.core.kernels'`.,This fails with ModuleNotFoundError: No module named 'tensorflow.core.kernels'.,1
"@chunduriv ,
I was able to reproduce the issue in tf v2.8 and [nightly](https://colab.research.google.com/gist/tilakrayal/cb4fb69f9096a4a2260acae5fd5fb9e7/nigtlytf_issues_fails_to_load_mobilenet_weights_in_2_8_but_not_2_7.ipynb), whereas in [v2.7](https://colab.research.google.com/gist/tilakrayal/182544e20eeb1d103f8d2cea85bdd781/tf_issues_fails_to_load_mobilenet_weights_in_2_8_but_not_2_7.ipynb) i was able to execute without facing any issue.Please find the gist.","""I was able to reproduce the issue in tf v2.8 and [nightly](https://colab.research.google.com/gist/tilakrayal/cb4fb69f9096a4a2260acae5fd5fb9e7/nigtlytf_issues_fails_to_load_mobilenet_weights_in_2_8_but_not_2_7.ipynb), whereas in [v2.7](https://",1
"@MisRight,
> ERROR: G:/tensorflow-r2.4.0-gpu/tensorflow-r2.4/tensorflow/compiler/xla/BUILD:423:1: C++ compilation of rule '//tensorflow/compiler/xla:literal' failed (Exit 2): python.exe failed: error executing command
This issue is related to Python and Numpy version compatibility issue. Tensorflow v2.4.1 source incompatible with Numpy version >=1.20.1. Tensorflow 2.4 support numpy ~= 1.19.5.
`pip install numpy==1.19.5`",ERROR: G:/tensorflow-r2.4.0-gpu/tensorflow-r2.4/tensorflow/compiler/xla/BUILD:423:1: C++ compilation of rule '//tensorflow/compiler/xla:literal' failed (Exit 2): python.exe failed: error executing command,1
"@shubhambagwari ,
We see that you are using tf version 1.15, 1.x is not actively supported, please update to latest tensorflow v2.8 and let us know if you are facing same issue.","""We see that you are using tf version 1.15, 1.x is not actively supported, please update to latest tensorflow v2.8 and let us know if you are facing same issue.""",1
Hi @ClaudioCimarelli ! You are using older versions(1.x versions) of Tensorflow which is not supported any more. Have you checked this [thread ](https://its.tntech.edu/display/MON/Installing+TensorFlow+in+Your+HPC+Account)on using Tensorflow on HPC cluster though?,"""You are using older versions(1.x versions) of Tensorflow which is not supported any more.""",1
TensorRT7_2 still fails with the same message.,"""TensorRT7_2 still fails with the same message.""",1
"I also ran into this issue on TF 2.5, which is using an outdated version of keras-preprocessing (i.e., v1.1.2). This issue was fixed via this [PR](https://github.com/keras-team/keras-preprocessing/pull/318), but had not made its way into the current TF versions. Though it seems like it will arrive soon based on [this commit](https://github.com/keras-team/keras/commit/373ad97c72ed1ac4b6898e85b2cfd7b016e4b469) from a month ago.","I also ran into this issue on TF 2.5, which is using an outdated version of keras-preprocessing (i.e., v1.1.2).",1
Hi @singlasahil14 ! It seems you are using older versions(1.x versions) of Tensorflow which is not supported any more. Attaching relevant [thread](https://stackoverflow.com/questions/45193238/why-out-channels-must-be-greater-then-channel-multiplier-in-channels-in-pointw?noredirect=1&lq=1) for reference though.,"""It seems you are using older versions(1.x versions) of Tensorflow which is not supported any more.""",1
"Please try with ""conda install -c anaconda cudatoolkit "" command . If that does not resolve the issue please check with instructions from [here ](https://www.tensorflow.org/install/pip) with TF 2.8 after activating Conda environment?","""conda install -c anaconda cudatoolkit "" command . If that does not resolve the issue please check with instructions from [here ](https://www.tensorflow.org/install/pip) with TF 2.8 after activating Conda environment?""",1
"@lhy2749 ,
We see that you are using tf version 1.15, 1.x is not actively supported, please update to latest stable version 2.8 and let us know if you are facing same issue.","""We see that you are using tf version 1.15, 1.x is not actively supported, please update to latest stable version 2.8 and let us know if you are facing same issue.""",1
"I believe the issue itself has not been resolved, If the tensorflow team has decided that the issue is not worth fixing, feel free to close it.","I believe the issue itself has not been resolved, If the tensorflow team has decided that the issue is not worth fixing, feel free to close it.",1
"@sanatmpa1 ,
I was able to reproduce the issue in tf v2.6 and nightly.Please find the gist [here](https://colab.research.google.com/gist/tilakrayal/a699c96140c7e85086d89e4bee47306b/untitled100.ipynb).
[EDIT] This is still an issue with `tf-nightly`(2.9.0-dev20220309)",I was able to reproduce the issue in tf v2.6 and nightly. Please find the gist [here](https://colab.research.google.com/gist/tilakrayal/a699c96140c7e85086d89e4bee47306b/untitled100.ipynb). [EDIT] This is still an issue with tf-nightly(2.9.0-dev20220309).,1
This issue is still reproducible on tf nightly-2.13.0-dev20230305 [gist](https://colab.sandbox.google.com/gist/tilakrayal/161482a5a0ee8e079bd1ac19ec1a3c87/untitled52.ipynb) version.,This issue is still reproducible on tf nightly-2.13.0-dev20230305 [gist](https://colab.sandbox.google.com/gist/tilakrayal/161482a5a0ee8e079bd1ac19ec1a3c87/untitled52.ipynb) version..,1
"@jvishnuvardhan ,
I was able to reproduce the issue in tensorflow [2.11.0-dev20220829](https://colab.research.google.com/gist/tilakrayal/39ee242dcd8f745fe98f4d46cacf3caf/2_4memory_leak-1.ipynb) it is giving error.Please find the gist here.",I was able to reproduce the issue in tensorflow [2.11.0-dev20220829](https://colab.research.google.com/gist/tilakrayal/39ee242dcd8f745fe98f4d46cacf3caf/2_4memory_leak-1.ipynb) it is giving error.Please find the gist here.,1
It looks like only the last commit got reverted. I don't think the issue (of build failing with CUDA 11.4 and CuDNN 8.2) will have resolved with reverting the last commit only.,I don't think the issue (of build failing with CUDA 11.4 and CuDNN 8.2) will have resolved with reverting the last commit only.,2
"> Unfortunately this change needs to be rolled back, it seems it breaks JAX build under CUDA 11.4 and CuDNN 8.2
@akuegel what are the issues? We can work on fixing them and re-merge.","""it seems it breaks JAX build under CUDA 11.4 and CuDNN 8.2""",2
"Unfortunately this change needs to be rolled back, it seems it breaks JAX build under CUDA 11.4 and CuDNN 8.2","""it seems it breaks JAX build under CUDA 11.4 and CuDNN 8.2""",2
"@kamil5b ,
The CUDA Driver version (528.02) may not compatible with the CUDA library i.e CUDA-11.2 here. You may try to install Driver version compatible with CUDA 11.2 library from [here](https://www.nvidia.com/Download/index.aspx). For example Driver Version 470.161.03 may be suitable for CUDA 11.2-11.4. Please try this and let us know if it works.",The CUDA Driver version (528.02) may not compatible with the CUDA library i.e CUDA-11.2 here.,2
"Any update? I tried locally, now it build, but without the CUDA backend included:
```
2023-01-09 22:03:33.475237: I tensorflow/compiler/xla/service/platform_util.cc:72] platform Host present but no XLA compiler available:
could not find registered compiler for platform Host -- was support for that platform linked in?
2023-01-09 22:03:33.475295: F tensorflow/compiler/xla/client/client_library.cc:127] Non-OK-status: client_status.status() status: NOT_F
OUND: no platforms found
```","I tried locally, now it build, but without the CUDA backend included: ",2
"@mohantym Uh, right, we can run scripts in colab... Try this [tf_280_xla_test.ipynb](https://colab.research.google.com/drive/1LTVJ7jRRzsODzMuPB-svocV4jcbx1SYY?usp=sharing). Just setting `CUDA_VISIBLE_DEVICES='1'` leaves it no GPU to use in yours, my bad. Updated commands.","""Just setting CUDA_VISIBLE_DEVICES='1' leaves it no GPU to use in yours, my bad.""",2
"@serdarakyol - Did you downgrade the CUDA to 11.2? Looking at Nvidia docs it looks like the display driver and cuda driver do not match - https://docs.nvidia.com/deploy/cuda-compatibility/#check-for-compatibility-support
I think TensorFlow should work for 11.2+ so you may not need to downgrade the driver or Cuda version. I have not verified this, but believe 11.2+ are compatible with 11.2.","""Looking at Nvidia docs it looks like the display driver and cuda driver do not match""",2
"CUDA version. needs to be 11.2+, from your config it looks like its 10.1. So, please see if you can upgrade your local CUDA version to 11.x. 11.2 builds should be compatible with anything 11.x","CUDA version. needs to be 11.2+, from your config it looks like its 10.1. So, please see if you can upgrade your local CUDA version to 11.x. 11.2 builds should be compatible with anything 11.x.",2
"The CI failed, but it doesn't seem related.","The CI failed, but it doesn't seem related.",3
Need to be removed from CI too. This PR is not sufficient.,Need to be removed from CI too. This PR is not sufficient.,3
"@gbaned there was failed ci.
Is there anything to do?",there was failed ci.,3
"I updated the PR. It was passing here, but failed CI compilation. It should be fixed now.",Failed CI compilation.,3
"Any update? It was approved 4 days ago, but isn't merged yet.
One CI failed, but the test failure doesn't seem related to my PR. It is a grappler error:
//tensorflow/python/grappler:remapper_test_gpu","""One CI failed, but the test failure doesn't seem related to my PR.""",3
"CI failure does not look related to these changes, seeing the same failure on #56345 (which has no code changes) so I assume this is noise.
```
//bazel_pip/tensorflow/python/kernel_tests/nn_ops:conv_ops_3d_test_cpu FLAKY, failed in 3 out of 33 in 300.3s
```",CI failure does not look related to these changes,3
Seems your Python paths are not set up properly. I'll try fixing the CI errors internally.,I'll try fixing the CI errors internally.,3
"@mihaimaruseac , any thought on the internal CI fail Internal",CI fail,3
"> Actually all of it was reverted:
https://github.com/tensorflow/tensorflow/commit/7a4d2e8b1a503a45ff86d40b0387fc832302379f
Why it doesn't show properly merged in this PR, I don't know :-(
Maybe it is easier to create a new PR?","""Why it doesn't show properly merged in this PR, I don't know""",4
@philipphack Can you please fix merge conflicts?,Can you please fix merge conflicts?,4
"This can't be merged until we actually have published a 2.12 release of TensorBoard. We're working on it right now and it should be ready later today, but please do not merge this until we let you know it's ready.","""We're working on it right now and it should be ready later today, but please do not merge this until we let you know it's ready.""",4
PR https://github.com/tensorflow/tensorflow/pull/59253 already went in. Could you please help resolve merge conflict?,"""Resolve merge conflict?""",4
"@gbaned, is there a chance for this PR to be accepted and merged?
I have rebased this PR twice and it is almost one year old as of today.
If it is not going to be merged, I suggest closing this PR.","I have rebased this PR twice and it is almost one year old as of today. If it is not going to be merged, I suggest closing this PR.",4
"> @trisolaran @akuegel Can one of you approve again this PR? It was already approved. I only fixed some builds issues after the approval.
I approved it 3 days ago, and I don't see another commit by you after that. So I guess we pulled in the latest state? I had to do a few more fixes, but should be merged soon.","I had to do a few more fixes, but should be merged soon.",4
There are merge conflicts and internal test failures. I will fix and merge. Please don't update the PR to address merge conflicts since it will revert the internal test failure fixes I am doing.,merge conflicts and internal test failures.,4
This merge would conflict with the commit https://github.com/tensorflow/tensorflow/commit/5984ea373e8804386fa60cf57eb6a18005c02b56. I'm closing the issue.,This merge would conflict with the commit https://github.com/tensorflow/tensorflow/commit/5984ea373e8804386fa60cf57eb6a18005c02b56. I'm closing the issue.,4
trying to manually merge it.,Trying to manually merge it.,4
"There'd be no harm in merging the PR. But there are a bunch of merge conflicts. Since Random seeds are such a common topic in software I'm not sure we need to be explaining it here. So I'm just closing, unless someone wants to fix the conflicts. Sorry!","""But there are a bunch of merge conflicts.""",4
My PR https://github.com/tensorflow/tensorflow/pull/57969 was approved 3 days ago but has not yet been merged. Can anyone please see if there is anything that needs to be addressed?,"""My PR https://github.com/tensorflow/tensorflow/pull/57969 was approved 3 days ago but has not yet been merged.""",4
"@sergeykozub @SandSnip3r @ekuznetsov139 due to merge conflict, landing this all at once might be very hard. It would be much easier to split it up.","""due to merge conflict, landing this all at once might be very hard.""",4
"The PR file changes LGTM and already approved / reviewed, please see the checks for the reason merging is blocked. Some of the CI failures seems to be transient issues and shall resolve after re-triggering those. For CLA please see [this](https://github.com/tensorflow/tensorflow/pull/56918/checks?check_run_id=7534827657) on how to resolve the check.","""The PR file changes LGTM and already approved / reviewed, please see the checks for the reason merging is blocked.""",4
"Any idea what I can do to resolve this?
> feedback/copybara â€” Google internal checks FAILED for runs with create time 2022-09-06T16:34:12.870440305Z.
I also need to resolve a merge conflict.",I also need to resolve a merge conflict.,4
"@haozha111 @gbaned I couldn't see relevant failures in above check, could you please let me know if something is blocking the merge?","I couldn't see relevant failures in above check, could you please let me know if something is blocking the merge?",4
"@bixia1: Please, don't merge that one into master. I have resolved the formal merge conflicts appeared after the merge of [PR#56942](https://github.com/tensorflow/tensorflow/pull/56942), but I need to fix something.","""I have resolved the formal merge conflicts appeared after the merge of [PR#56942](https://github.com/tensorflow/tensorflow/pull/56942), but I need to fix something.""",4
@cheshire any idea why it isn't merged while the other PR got merged?,"""why it isn't merged while the other PR got merged?""",4
"@gbaned @haozha111 This is yet to merge, could you please check once?","""This is yet to merge, could you please check once?""",4
"@gbaned We could not merge this.
@mdanatg We lost the PR... What you want to do?",We could not merge this.,4
"Added the patch for now, this actually broke when https://github.com/tensorflow/tensorflow/pull/56446 merged, which is why I didn't initially have this issue","Added the patch for now, this actually broke when https://github.com/tensorflow/tensorflow/pull/56446 merged, which is why I didn't initially have this issue.",4
"I submitted the PR https://github.com/tensorflow/tensorflow/pull/56620 to remove uses of no_oss_py2, which has been approved but not merged yet, though not sure why.
So it seems that the ARM_CI and ARM_CD workflows are only running the pip tests. Are there plans to also run the nonpip tests on the source code directly?
The current test flags for these ARM workflows include ""-requires-gpu,-gpu,-tpu,"" which are not used in the x86 pip tests.","""I submitted the PR https://github.com/tensorflow/tensorflow/pull/56620 to remove uses of no_oss_py2, which has been approved but not merged yet, though not sure why.""",4
"I think this was merged with https://github.com/tensorflow/tensorflow/commit/299cb76dd913e7bb0349a13c1165459dac4ea81e but the PR is not closed and put in a merged status.
We have collected this case in https://github.com/tensorflow/community/issues/413",I think this was merged with https://github.com/tensorflow/tensorflow/commit/299cb76dd913e7bb0349a13c1165459dac4ea81e but the PR is not closed and put in a merged status.,4
@gbaned Could you merge the PR?,Could you merge the PR?,4
"@LukeWood too late, It was already merged. If @wangpengmit is ok with this additional API change I could eventually open a new one.","too late, It was already merged.",4
It might have been a wrong-way merge or something like that. At this point it's usually easier to just close it and make a new PR from scratch.,"""Wrong-way merge""",4
@bixia1 I had to resolve another merge conflict that came up in the last few days. Does the PR need to be re-approved?,I had to resolve another merge conflict that came up in the last few days.,4
@mahmoud-abuzaina i think you need to rebase this PR to the head to trigger the tests,i think you need to rebase this PR to the head to trigger the tests.,5
NNTest and TPUEmbeddingForServingTest were still calling `embedding_lookup_ragged`. The other test failures in the log don't seem to be related to this change.,The other test failures in the log don't seem to be related to this change.,5
This keeps failing internal tests. Let me see if I can quickly generate a fix,This keeps failing internal tests.,5
"Seems like almost all tests succeeded except for one, but I am not sure what to make of this. I don't know if this PR is what breaks this?
```
tensorflow/c/eager/c_api_test.cc:681: Failure
Expected equality of these values:
orig_ptr
Which is: 0x55ab336cfc00
TF_TensorData(t)
Which is: 0x7f5d90089f40
```","seems like almost all tests succeeded except for one, but I am not sure what to make of this. I don't know if this PR is what breaks this",5
"@bixia1: It is just a first draft. The test doesn't even work. In the meantime, it makes sense to review the refactoring of `tensorflow/python/compiler/tensorrt/test/BUILD`",The test doesn't even work.,5
I can see some tests are failed but the log shows the failure is unrelated to this PR. Can you help check? @reedwm,I can see some tests are failed but the log shows the failure is unrelated to this PR.,5
"> This needs to get fixed, as we are not testing depthwise convolutions currently. @duncanriach, do you want to fix this? A quick fix would be to add `@unittest.skip(""Test currently fails"")` for the two failing test methods.
Yes, I'll work on this. It's weird that these tests are failing because I thought I ran them successfully for PR [55657](https://github.com/tensorflow/tensorflow/pull/55657).","""It's weird that these tests are failing because I thought I ran them successfully for PR [55657](https://github.com/tensorflow/tensorflow/pull/55657)...""",5
"Many tests failed, will email a log",Many tests failed.,5
"Update: test still fails on commit `55645ca964508507890529a71591f51a344a6356` April 9
test passes with ``--config=opt``","""test still fails on commit 55645ca964508507890529a71591f51a344a6356 April 9 test passes with --config=opt""",5
"@PatriceVignola We only run TensorFlow presubmit tests before merging. After merging, PRs could still be reverted if they broke TensorFlow nightly tests or other internal tests (e.g., unit / integration tests of internal applications that use TensorFlow). In this case, it broke an internal test.","""In this case, it broke an internal test.""",5
This PR got reverted because it broke internal tests. Will add this to the list of `DEVICE_DEFAULT` ops to revisit / investigate later.,"""PR got reverted because it broke internal tests""",5
"> @drivanov this test fail, see [log](https://github.com/tensorflow/tensorflow/files/8265934/boolpr.log)
Fixed.","""this test fail, see [log](https://github.com/tensorflow/tensorflow/files/8265934/boolpr.log) Fixed."")",5
"@drivanov this test fail, see
[log](https://github.com/tensorflow/tensorflow/files/8265934/boolpr.log)","""this test fail, see [log](https://github.com/tensorflow/tensorflow/files/8265934/boolpr.log)""",5
"I got this test failur
[casttest.log](https://github.com/tensorflow/tensorflow/files/8155552/casttest.log)
e",I got this test failur,5
It seems the PR has been hanging for a while. I see some tests fail but they seem unrelated to the PR. Can you help check? @awpr @jurahul,I see some tests fail but they seem unrelated to the PR.,5
"Thanks for creating the gist.
However, as I said, it is crucial to run it on Apple M1 hardware to reproduce it. In your gist, I see that you use an Nvidia GPU.
Also, you did not exactly use the commits I specified, although this probably should not matter.","""You did not exactly use the commits I specified, although this probably should not matter.""",6
"3 commits for a single line change? Can you please merge the commits in just one?
In general, we don't want to insert all and every links to the README. There are too many and some don't have the same quality as others. It takes too much time to evaluate the materials, so it is better to only include links that Google has vetted. As such, I don't think this PR is worthwhile.",3 commits for a single line change?,6
"Can you make one single commit with the change in the first file? 7 commits for just one single file change are a little bit too much.
You can squash all commits to a single one too if you don't want to open a separate PR.",7 commits for just one single file change are a little bit too much.,6
Can you squash these commits please? It doesn't make sense to have 5 commits for a line change and one extra empty line,It doesn't make sense to have 5 commits for a line change,6
"Yeah, we already split it into other PRs. It was much larger. Also, I understand larger commits are not a good idea, but in this case changes really need to go together
Also note, most of the code changes are ROCm specific. About half(may be more) the files touched are only for ROCm. In common files, almost all the changes are again ROCm specific. They are #defines like TENSORFLOW_ROCM","""I understand larger commits are not a good idea, but in this case changes really need to go together""",6
"I see there are 8 commits, can you squash them into 1 commit?","I see there are 8 commits, can you squash them into 1 commit?",6
Could you please squash the commits?,Could you please squash the commits?,6
Can you squash the commits?,Can you squash the commits?,6
Please squash the commits.,"""Please squash the commits.""",6
